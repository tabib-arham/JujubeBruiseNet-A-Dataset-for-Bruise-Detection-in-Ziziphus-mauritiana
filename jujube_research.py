# -*- coding: utf-8 -*-
"""jujube_research.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZerMdixBTFe4d33tiIRAkEFfxcpGRb3Y

load data
"""

from google.colab import drive
drive.mount('/content/drive')

import os
dataset = '/content/drive/MyDrive/jujube_research/dataset'

classes = ["bruised", "healthy"]
folders_found = [cls for cls in classes if os.path.isdir(os.path.join(dataset, cls))]

if set(folders_found) == set(classes):
    print("Found both 'bruise' and 'health' folders.")
else:
    print("Warning: Expected folders not found! Found:", folders_found)

# Count images in each class
for cls in folders_found:
    num_images = len(os.listdir(os.path.join(dataset, cls)))
    print(f"{cls}: {num_images} images")

# Install compatible NumPy version

!pip install "numpy>=1.20,<2.0" --force-reinstall
!pip install scikit-image scipy --no-cache-dir

import os
import cv2
import numpy as np
from tqdm import tqdm
from skimage.filters import gabor
from skimage.feature import graycomatrix, graycoprops

# Set target image size
image_size = (512, 512)


def preprocess_to_thermal(image_path):
    img = cv2.imread(image_path)

    if img is None:
        print(f"Error reading {image_path}")
        return None

    # Step 1: Resize image
    img = cv2.resize(img, image_size)


    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    l = clahe.apply(l)
    enhanced_img = cv2.merge((l, a, b))
    enhanced_img = cv2.cvtColor(enhanced_img, cv2.COLOR_LAB2BGR)

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)




    glcm = graycomatrix(gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)
    contrast = graycoprops(glcm, 'contrast')[0, 0]
    correlation = graycoprops(glcm, 'correlation')[0, 0]

    return contrast, correlation

# Define dataset and output paths
dataset = '/content/drive/MyDrive/jujube_research/dataset'
output_dir = os.path.join('/content/drive/MyDrive', 'Final_Augmented_Dataset')
os.makedirs(output_dir, exist_ok=True)

# Process all images
for cls in tqdm(os.listdir(dataset), desc="Processing Classes"):
    class_path = os.path.join(dataset, cls)
    output_class_path = os.path.join(output_dir, cls)
    os.makedirs(output_class_path, exist_ok=True)

    total_images = 0

    for img_name in tqdm(os.listdir(class_path), desc=f"Processing {cls}"):
        img_path = os.path.join(class_path, img_name)
        thermal_img = preprocess_to_thermal(img_path)

        if thermal_img is not None:
            # Save the thermal image
            cv2.imwrite(os.path.join(output_class_path, img_name), thermal_img)
            total_images += 1

    print(f"âœ… Total images (thermal) in class '{cls}': {total_images}")

print("âœ… Thermal Preprocessing Complete! Check 'Final_Augmented_Dataset'.")

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Flatten # Import Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
import matplotlib.pyplot as plt

# Define dataset path (change if needed)
dataset_path = "/content/drive/MyDrive/Final_Augmented_Dataset"

# Image size and batch size
img_size = (512, 512)
batch_size = 32

# Load dataset without further preprocessing (since it's already done)
datagen = ImageDataGenerator(validation_split=0.2)  # Split: 80% train, 20% validation
# Load training data
train_data = datagen.flow_from_directory(
    dataset_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode="binary",
    subset="training"
)

# Load validation data
val_data = datagen.flow_from_directory(
    dataset_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode="binary",
    subset="validation"
)

print("Class Labels:", train_data.class_indices)

# Define CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(512, 512, 3)),
    MaxPooling2D(2, 2),
    BatchNormalization(),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    BatchNormalization(),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    BatchNormalization(),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')  # Binary classification: Bruised vs Healthy
])

# Compile Model
model.compile(optimizer=Adam(learning_rate=0.0001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Print Model Summary
model.summary()

history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=10,
    steps_per_epoch=len(train_data),
    validation_steps=len(val_data),

)

"""loss graph"""

# âœ… Plot Training History
plt.figure(figsize=(12, 5))

# ðŸ”¹ Plot Accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Training vs Validation Accuracy")
plt.legend()
plt.grid(True)

# ðŸ”¹ Plot Loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss', color='blue')
plt.plot(history.history['val_loss'], label='Validation Loss', color='red')
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Training vs Validation Loss")
plt.legend()
plt.grid(True)

# âœ… Show Plots
plt.tight_layout()
plt.show()

"""AOC ROC"""

from sklearn.metrics import roc_curve, auc

# Step 1: Get True Labels & Predictions
y_true = val_data.classes  # Actual labels
y_pred_prob = model.predict(val_data)  # Predicted probabilities

# Step 2: Compute ROC Curve
fpr, tpr, _ = roc_curve(y_true, y_pred_prob)
roc_auc = auc(fpr, tpr)

# Step 3: Plot ROC Curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal Line
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate (FPR)")
plt.ylabel("True Positive Rate (TPR)")
plt.title("Receiver Operating Characteristic (ROC) Curve")
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

"""confusion matrics"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Step 1: Get True Labels & Predictions
y_true = val_data.classes  # Actual labels
y_pred_prob = model.predict(val_data)  # Predicted probabilities
y_pred = (y_pred_prob > 0.5).astype(int)  # Convert to binary (0 or 1)

# Step 2: Compute Confusion Matrix
cm = confusion_matrix(y_true, y_pred)

# Step 3: Plot Confusion Matrix
plt.figure(figsize=(6, 5))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Healthy', 'Bruised'])
disp.plot(cmap='Blues', values_format='d')
plt.title("Confusion Matrix")
plt.show()

"""MODEL: VGG16"""

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint
import matplotlib.pyplot as plt

# Define dataset path (Change if needed)
dataset_path = "/content/drive/MyDrive/Final_Augmented_Dataset"

# Image size and batch size
img_size = (224, 224)  # VGG16 requires 224x224 images
batch_size = 32

# Load dataset without further preprocessing (since it's already done)
datagen = ImageDataGenerator(validation_split=0.2)  # Split: 80% train, 20% validation

train_data = datagen.flow_from_directory(
    dataset_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode="binary",
    subset="training"
)

val_data = datagen.flow_from_directory(
    dataset_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode="binary",
    subset="validation"
)

print("Class Labels:", train_data.class_indices)

# Load VGG16 model (Pre-trained on ImageNet)
base_model = VGG16(weights="imagenet", include_top=False, input_shape=(224, 224, 3))

# Freeze base model layers (We only train the top layers)
for layer in base_model.layers:
    layer.trainable = False

# Define Custom Model (Add Fully Connected Layers)
model = Sequential([
    base_model,
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')  # Binary classification (Bruised vs. Healthy)
])

# Compile Model
model.compile(optimizer=Adam(learning_rate=0.0001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Print Model Summary
model.summary()

# Define checkpoint path
checkpoint_path = "/content/drive/MyDrive/training_checkpoints/vgg16_checkpoint.h5"

# Model Checkpoint Callback
checkpoint_callback = ModelCheckpoint(
    filepath=checkpoint_path,
    save_best_only=True,
    monitor='val_accuracy',
    mode='max',
    verbose=1
)

# Load previous checkpoint if available
if os.path.exists(checkpoint_path):
    print("Loading weights from previous checkpoint...")
    model.load_weights(checkpoint_path)

# Train the model
history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=20,
    steps_per_epoch=len(train_data),
    validation_steps=len(val_data),
    callbacks=[checkpoint_callback]
)

# Save Final Model
model.save("/content/drive/MyDrive/final_vgg16_model.h5")

print("âœ… VGG16 Training Complete! Model Saved.")